### Мотивация
В задаче *IR* набирает популярность *BERT*, который показывают высокую эффективность в сравнении с другими методами, но computational costs растут в десятки раз, так как при использовании такого подхода нам необходимо проскорить каждую *d* (document) - *q* (query) пару. Авторы предлагают алгоритм который сначала независимо обрабатывает *query* и *document*, с эмбеддингами которых позднее производит *pruning-friendly* операции, при которых не нужно рассматривать каждого возможного кандидата.

![[Pasted image 20241228012319.png|600]]


*Примечание: под "NLU augmentation" подразумевается техника расширения, перефраза начального вопроса для большего покрытия*
По результатам бенчамарка видно, что *ColBERT* позволяет достичь результатов сопоставимых с *BERT*, но обладает гораздо лучшей скоростью.

Так как *BERT* не позволял использовать его в production из-за высокой latency, производились исследования с аумгентацией изначальных вопросов с целью лучшего поиска.

![[Pasted image 20241228013738.png|700]]  

На картинке выше схематично представлены существующие подходы в решении данной задачи. 

*a)* *Representation-focused rankers*, которые независимо получают эмбеддинги *q* и *d* и рассчитывают similarity score между двумя векторами. Такой подход используется в DSSM, где эмбеддинги запроса и документа считаются независимо, благодаря чему документы запросов можно предварительно посчитать в оффлайне. 

*b)* *Interaction-based rankers*, которые в отличие от варианта *a* эмбеддят не полностью текст, а отдельные слова, фразы, из эмбеддингов которых составляется матрица размерности *d_shape x q_shape*, которая позднее обрабатывается с помощью нейронной сети(CNN, MLP, Kernels). 

*c)* *All-to-all interaction*. Модель, которая одновременно обрабатывает *query* и *document*(*cross-encoder* с transformer)
Пример:
```css
[CLS] query_token_1 query_token_2 ... [SEP] document_token_1 document_token_2 ... [SEP]
```
Данная архитектура позволяет достичь высокой точности, но требует больше вычислительных ресурсов


### ColBERT

![[Pasted image 20241231141128.png|500]]

<div align="left">
  Рисунок 3: архитектура ColBERT
</div>

###  Объяснение архитектуры ColBERT

1. **Кодирование запросов и документов:**
   - Запрос `q` преобразуется энкодером `fQ` в набор эмбеддингов `Eq`.
   - Документ `d` преобразуется энкодером `fD` в набор эмбеддингов `Ed`.
   - Каждый эмбеддинг внутри `Eq` и `Ed` учитывает контекст остальных терминов внутри запроса и документа соответственно.

2. **Late Interaction (позднее взаимодействие):**
   - Для эмбеддинга каждого токена `v ∈ Eq` из запроса ищется **максимальное сходство** с эмбеддингами в `Ed` (эмбеддинги документа). Это сходство вычисляется с использованием метрики:
     - **Косинусное сходство**.
     - **L2 расстояние** (в качестве альтернативы).
   - Результат сходства между `v` и `Ed` называется **MaxSim**.

3. **Итоговая оценка релевантности:**
   - После вычисления максимального сходства для всех эмбеддингов из `Eq` эти значения суммируются, чтобы получить финальный скор релевантности между запросом `q` и документом `d`.

4. **Интуитивный смысл:**
   - Каждый термин `tq` из запроса мягко ищет наиболее подходящий термин `td` в документе.
   - Сила соответствия между `tq` и `td` определяется через самое большое сходство.
   - Финальный релевантный скор оценивает, насколько документ в целом "покрывает" запрос, агрегируя эти локальные совпадения.


1. **Формула для представления запроса:**

   $$\large E_q = \text{Normalize}(\text{Linear}(\text{BERT}("[Q] \; q_0 \; q_1 \; \dots \; q_l \; \# \# \; \dots \; \#")))$$

2. **Формула для представления документа:**

   $$\large E_d = \text{Filter}(\text{Normalize}(\text{Linear}(\text{BERT}("[D] \; d_0 \; d_1 \; \dots \; d_n"))))$$
3. Формула, описывающая Late Interaction:


$$
\large S_{q,d} := \sum_{i \in |E_q|} \max_{j \in |E_d|} E_{q_i} \cdot E_{d_j}^T
$$

