![[Pasted image 20241025183556.png|350]]
### LoRA обладает несколькими ключевыми преимуществами:

- Предобученная модель может быть использована для создания множества небольших LoRA-модулей для различных задач. Мы можем заморозить общую модель и эффективно переключать задачи, заменяя матрицы \( A \) и \( B \) на Рисунке 1, что значительно снижает требования к хранилищу и накладные расходы при переключении задач.

- LoRA делает обучение более эффективным и снижает аппаратные требования для начала работы до 3 раз при использовании адаптивных оптимизаторов, так как нам не нужно вычислять градиенты или поддерживать состояние оптимизатора для большинства параметров. Вместо этого мы оптимизируем только внедренные, гораздо меньшие матрицы низкого ранга.

- Наш простой линейный дизайн позволяет нам объединять обучаемые матрицы с замороженными весами при разворачивании, **не увеличивая задержку на инференсе** по сравнению с полностью дообученной моделью благодаря такой конструкции.

При  finetuning'е модели мы обновляем все веса $\Phi$,  в то время как в LoRA мы обучаем лишь адаптер $\Phi_0$, который содержит сильно меньше обучаемых параметров
$$
\max_{\Phi} \sum_{(x, y) \in \mathbb{Z}} \sum_{t=1}^{|y|} \log \left( P_{\Phi} (y_t | x, y_{<t}) \right) \tag{1}
$$



$$
\max_{\Theta} \sum_{(x, y) \in \mathbb{Z}} \sum_{t=1}^{|y|} \log \left( p_{\Phi_0 + \Delta \Phi(\Theta)} (y_t | x, y_{<t}) \right) \tag{2}
$$

